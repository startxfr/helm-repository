# Default values for configuration of a STARTX cluster
# see values.yaml for explanation on each params
context: 
  scope: startx
  cluster: localhost
  environment: dev
  component: vault
  app: startx-vault
route: 
  enabled: true
project: 
  context: 
    scope: startx
    cluster: localhost
    environment: dev
    component: vault
    app: startx-vault
  project: 
    type: project
    name: startx-vault
    display_name: STARTX Infra - VAULT
    description: STARTX Private Vault storage & control plane
  rbac: 
    enabled: true
    groups: 
    - id: dev
      name: dev
      clusterRole: view
    - id: devops
      name: devops
      clusterRole: admin
    - id: ops
      name: ops
      clusterRole: admin
    user: 
    - id: vault-sa
      name: system:serviceaccount:startx-vault:vault
      clusterRole: edit
    - id: vault-agent-injector-sa
      name: system:serviceaccount:startx-vault:vault-agent-injector
      clusterRole: admin
  networkpolicy: 
    enabled: false
  limits: 
    enabled: true
    rules:  |
      limits:
        - type: "Pod"
          min:
            cpu: 10m
            memory: 32Mi
          max:
            cpu: "500m"
            memory: "512Mi"
        - type: "Container"
          default:
            cpu: 100m
            memory: 64Mi
          defaultRequest:
            cpu: 100m
            memory: 64Mi
          min:
            cpu: 10m
            memory: 32Mi
          max:
            cpu: "500m"
            memory: "512Mi"
  quotas: 
    enabled: true
    rules:  |
      hard:
        limits.cpu: "2"
        limits.memory: "1500Mi"
        requests.cpu: "1"
        requests.memory: "512Mi"
        requests.storage: "0"
        persistentvolumeclaims: "0"
        ephemeral-storage: "0" 
        gp2.storageclass.storage.k8s.io/requests.storage: "0"
        gp2.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-generic-retain.storageclass.storage.k8s.io/requests.storage: "0"
        aws-generic-retain.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-generic-delete.storageclass.storage.k8s.io/requests.storage: "0"
        aws-generic-delete.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-fast-retain.storageclass.storage.k8s.io/requests.storage: "0"
        aws-fast-retain.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-fast-delete.storageclass.storage.k8s.io/requests.storage: "0"
        aws-fast-delete.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-slow-retain.storageclass.storage.k8s.io/requests.storage: "0"
        aws-slow-retain.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        aws-slow-delete.storageclass.storage.k8s.io/requests.storage: "0"
        aws-slow-delete.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        ocs-generic-delete.storageclass.storage.k8s.io/requests.storage: "0"
        ocs-generic-delete.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        ocs-generic-retain.storageclass.storage.k8s.io/requests.storage: "0"
        ocs-generic-retain.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        ocs-fs-delete.storageclass.storage.k8s.io/requests.storage: "0"
        ocs-fs-delete.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        ocs-fs-retain.storageclass.storage.k8s.io/requests.storage: "0"
        ocs-fs-retain.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        ocs-storagecluster-ceph-rbd.storageclass.storage.k8s.io/requests.storage: "0"
        ocs-storagecluster-ceph-rbd.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        openshift-storage.noobaa.io.storageclass.storage.k8s.io/requests.storage: "0"
        openshift-storage.noobaa.io.storageclass.storage.k8s.io/persistentvolumeclaims: "0"
        pods: "6"
        services: "5"
        services.loadbalancers: "0"
        services.nodeports: "0"
        secrets: "35"
        configmaps: "0"
        replicationcontrollers: "0"
        openshift.io/imagestreams: "0"
        count/replicasets.apps: "4"
        count/daemonsets.apps: "2"
        count/deployments.apps: "2"
vault:
  global:
    enabled: true
    imagePullSecrets: []
    tlsDisable: true
  injector:
    enabled: true
    image:
      repository: "hashicorp/vault-k8s"
      tag: "0.3.0"
      pullPolicy: IfNotPresent
    agentImage:
      repository: "vault"
      tag: "1.4.0"
    authPath: "auth/kubernetes"
    logLevel: "info"
    logFormat: "standard"
    revokeOnShutdown: false
    namespaceSelector: {}
    certs:
      secretName: null
      caBundle: ""
      certName: tls.crt
      keyName: tls.key
    resources:
      requests:
        memory: 64Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 250m
    extraEnvironmentVars: {}
    affinity: null
    tolerations: null
    nodeSelector: null
  server:
    image:
      repository: "vault"
      tag: "1.4.0"
      pullPolicy: IfNotPresent
    updateStrategyType: "OnDelete"
    resources:
      requests:
        memory: 64Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 250m
    ingress:
      enabled: false
      labels: {}
      annotations: {}
      hosts:
        - host: chart-example.local
          paths: []
      tls: []
    authDelegator:
      enabled: true
    extraContainers: null
    shareProcessNamespace: false
    extraArgs: ""
    readinessProbe:
      enabled: true
    livenessProbe:
      enabled: true
      path: "/v1/sys/health?standbyok=true"
      initialDelaySeconds: 60
    preStopSleepSeconds: 5
    extraEnvironmentVars: {}
    extraSecretEnvironmentVars: []
    extraVolumes: []
    affinity: |
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ template "vault.name" . }}
                app.kubernetes.io/instance: "{{ .Release.Name }}"
                component: server
            topologyKey: kubernetes.io/hostname
    tolerations: {}
    nodeSelector: {}
    extraLabels: {}
    annotations: {}
    service:
      enabled: true
      clusterIP: None
      type: ClusterIP
      port: 8200
      targetPort: 8200
      annotations: {}
    dataStorage:
      enabled: true
      size: 10Gi
      storageClass: null
      accessMode: ReadWriteOnce
    auditStorage:
      enabled: false
      size: 10Gi
      storageClass: null
      accessMode: ReadWriteOnce
    dev:
      enabled: true
    standalone:
      enabled: "-"
      config: |
        ui = true

        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }
        storage "file" {
          path = "/vault/data"
        }

        # Example configuration for using auto-unseal, using Google Cloud KMS. The
        # GKMS keys must already exist, and the cluster must have a service account
        # that is authorized to access GCP KMS.
        #seal "gcpckms" {
        #   project     = "vault-helm-dev"
        #   region      = "global"
        #   key_ring    = "vault-helm-unseal-kr"
        #   crypto_key  = "vault-helm-unseal-key"
        #}
    ha:
      enabled: false
      replicas: 3
      raft:
        enabled: false
        config: |
          ui = true

          listener "tcp" {
            tls_disable = 1
            address = "[::]:8200"
            cluster_address = "[::]:8201"
          }

          storage "raft" {
            path = "/vault/data"
          }

          service_registration "kubernetes" {}
      config: |
        ui = true

        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }
        storage "consul" {
          path = "vault"
          address = "HOST_IP:8500"
        }

        service_registration "kubernetes" {}

        # Example configuration for using auto-unseal, using Google Cloud KMS. The
        # GKMS keys must already exist, and the cluster must have a service account
        # that is authorized to access GCP KMS.
        #seal "gcpckms" {
        #   project     = "vault-helm-dev-246514"
        #   region      = "global"
        #   key_ring    = "vault-helm-unseal-kr"
        #   crypto_key  = "vault-helm-unseal-key"
        #}
      disruptionBudget:
        enabled: true
        maxUnavailable: null
    serviceAccount:
      annotations: {}
  ui:
    enabled: true
    serviceType: "ClusterIP"
    serviceNodePort: null
    externalPort: 8200
    annotations: {}