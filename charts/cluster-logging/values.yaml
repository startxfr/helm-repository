# Default values for cluster-logging.

# Application deployment context
context:  &context
  # Name of the global scope for this application (organisational tenant)
  scope: myscope
  # Name of the cluster running this application (plateform tenant)
  cluster: default
  # Name of the environement for this application (ex: dev, factory, preprod or prod)
  environment: myenv
  # Component name of this application (logical tenant)
  component: mycomponent
  # Application name (functionnal tenant, default use Chart name)
  app: default-logging
  # Version name of this application (default use Chart appVersion)
  version: "6.2.1"

# configuration of the logging service
logging:
  # Enable the deployment of the logging service
  enabled: false
  # Enable the deployment of the logging service into infra nodes
  infra_enabled: false
  # Activate the manager as a helm hook
  hooked: false
  # set the management state to use
  managementState: "Managed"
  # Section for external exposition of elasticsearch
  expose:
    # Enable creating the route
    enabled: false
    # CACertificate for the elasticsearch. Defined in a secret (see bellow)
    destinationCACert: |
      -----BEGIN CERTIFICATE-----
      place here your elasticsearch certificate. 
      You can get it with 
      oc extract secret/elasticsearch \
      -n openshift-logging --to=. --keys=admin-ca && \
      cat admin-ca
      -----END CERTIFICATE-----
  # configuration of the elasticsearch service
  elasticsearch:
    # Enable the deployment of the elasticsearch service
    enabled: false
    # number of elasticsearch instances
    replicas: 3
    # the redundancy policy applied to this elastic (could be ZeroRedundancy, SingleRedundancy, MultipleRedundancy and FullRedundancy)
    redundancyPolicy: SingleRedundancy
    # Resource spec for elasticsearch pods
    resources:
      limits:
        cpu: 1
        memory: 500Mi
      requests:
        cpu: 500m
        memory: 100Mi
    # configuration of the storage
    storage: 
      # name of the storageclass to use
      class: gp3-csi
      # the size of the storage to provision
      size: "200G"
  # configuration of the kibana service
  kibana:
    # Enable the deployment of the kibana service
    enabled: true
    # number of kibana instances
    replicas: 3
    # Resource spec for kibana pods
    resources:
      limits:
        cpu: 1
        memory: 500Mi
      requests:
        cpu: 500m
        memory: 100Mi
  # configuration of the curation service
  curation:
    # Enable the deployment of the curation service
    enabled: true
    # Configuration the schedulling of curator
    schedule: "30 3 * * *"
    # # Resource spec for curation pods
    # resources:
    #   requests:
    #     cpu: "100m"
  # configuration of the collector service
  collector:
    # Enable the deployment of the collector service
    enabled: true
    # Type of collector engine (must be vector or fluentd. default is vector)
    type: "vector"
    # # Resource spec for collector pods
    # resources:
    #   requests:
    #     cpu: "100m"

# configuration of the eventrouter service
eventrouter:
  # Enable the deployment of the eventrouter service
  enabled: false
  # number of eventrouter instances
  replicas: 1
  # Resource spec for eventrouter pods
  resources:
    limits:
      cpu: 400m
      memory: 512Mi
    requests:
      cpu: "100m"
      memory: 128Mi

# configuration of the logforwarder service
logforwarder:
  # Enable the deployment of the logforwarder service
  enabled: false
  # spec of the og forwarder
  spec: |
    pipelines: 
    - name: all-to-default
      inputRefs:
      - infrastructure
      - application
      - audit
      outputRefs:
      - default
  # Configuration of the secret for external logging stack
  secret:
    # Enable the creation of the external secret configuration
    enabled: false
    # Name of the secret (default is elk-secret)
    name: elasticsearch-external
    # CA Bundle that sign the certificate
    CABundle: |-
      ----BEGIN CERTIFICATE-----
      MIIEWjxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      -----END CERTIFICATE-----
      ----BEGIN CERTIFICATE-----
      MIIEWjxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      -----END CERTIFICATE-----
    # TLS certificate
    tlsCrt: |-
      ----BEGIN CERTIFICATE-----
      MIIEWjxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      -----END CERTIFICATE-----
    # Private key of the TLS certificate
    tlsKey: |-
      -----BEGIN RSA PRIVATE KEY-----
      MIIJKAyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy
      yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy
      -----END RSA PRIVATE KEY-----
    # Login to the external Elastic endpoint
    username: mypwd
    # Password to the external Elastic endpoint
    password: mypwd

# Configuration of the project (see https://helm-repository.readthedocs.io/en/latest/charts/project)
project: 
  enabled: false
  context: 
    <<: *context
  project: 
    enabled: false
    type: namespace
    name: "logging-operator"
    display_name: Operator LOGGING
    description: LOGGING operators configured by startx
  rbac: 
    enabled: false
    groups: 
    - id: devops-view
      name: devops
      role: view
    - id: ops-admin
      name: ops
      role: admin
  networkpolicy: 
    enabled: false
  limits: 
    enabled: false
  quotas: 
    enabled: false

# Configuration of the operator (see https://helm-repository.readthedocs.io/en/latest/charts/operator)
operator:
  enabled: false
  context: 
    <<: *context
  subscription:
    enabled: true
    name: "cluster-logging"
    namespace: "openshift-logging"
    version: "6.2.1"
    operator: 
      channel: "stable-6.2"
      name: cluster-logging
      installPlanApproval: Automatic
      # csv: cluster-logging
      source: 
        name: redhat-operators
        namespace: openshift-marketplace
      config: 
        infra: true
  operatorGroup:
    enabled: true
    hooked: false
    name: "openshift-logging"
    namespace: "openshift-logging"
    providedAPIs: "ClusterLogForwarder.v1.logging.openshift.io,ClusterLogging.v1.logging.openshift.io,LogFileMetricExporter.v1alpha1.logging.openshift.io"


# Configuration of the elasticSearch operator (see https://helm-repository.readthedocs.io/en/latest/charts/operator)
operatorElastic:
  enabled: false
  context: 
    <<: *context
  subscription:
    enabled: true
    hooked: false
    name: "elasticsearch-operator"
    namespace: "openshift-operators-redhat"
    version: "5.8.14"
    operator: 
      channel: "stable"
      name: elasticsearch-operator
      installPlanApproval: Automatic
      # csv: elasticsearch-operator
      source: 
        name: redhat-operators
        namespace: openshift-marketplace
      config: 
        infra: true
  operatorGroup:
    enabled: true
    hooked: false
    target: "all-ns"
    name: "openshift-operators-redhat"
    namespace: "openshift-operators-redhat"
    providedAPIs: "Elasticsearch.v1.logging.openshift.io,Kibana.v1.logging.openshift.io,LogFileMetricExporter.v1alpha1.logging.openshift.io"

# Configuration of the loki operator (see https://helm-repository.readthedocs.io/en/latest/charts/operator)
operatorLoki:
  enabled: false
  context: 
    <<: *context
  subscription:
    enabled: true
    hooked: false
    name: "loki-operator"
    namespace: "openshift-operators-redhat"
    version: "6.2.1"
    operator: 
      channel: "stable-6.2"
      name: loki-operator
      installPlanApproval: Automatic
      # csv: loki-operator
      source: 
        name: redhat-operators
        namespace: openshift-marketplace
      config: 
        infra: true
  operatorGroup:
    enabled: true
    hooked: false
    target: "all-ns"
    name: "openshift-operators-redhat"
    namespace: "openshift-operators-redhat"
    providedAPIs: "AlertingRule.v1.loki.grafana.com,LokiStack.v1.loki.grafana.com,RecordingRule.v1.loki.grafana.com,RulerConfig.v1.loki.grafana.com"
